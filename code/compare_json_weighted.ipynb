{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NOTEBOOK UPDATED BY AI ASSISTANT\n",
        "# Date: 2026-01-05\n",
        "# Status: Weighted scoring, labels, and colors enabled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Accuracy Report\n",
        "This notebook provides a visual analysis of the extraction accuracy compared to the ground truth across multiple documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, difflib, os, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "batch_summary = []\n",
        "FIELD_WEIGHTS = {\n",
        "    \"invoice_number\": 3.0, \n",
        "    \"total_amount\": 5.0, \n",
        "    \"net_amount\": 3.0, \n",
        "    \"invoice_date\": 2.0, \n",
        "    \"total_tax_amount\": 2.0,\n",
        "    \"supplier_tax_id\": 2.0,\n",
        "    \"customer_tax_id\": 2.0,\n",
        "    \"line_items\": {\n",
        "        \"description\": 0.5, \n",
        "        \"quantity\": 1.0, \n",
        "        \"unit_price\": 1.5, \n",
        "        \"amount\": 2.0\n",
        "    }\n",
        "}\n",
        "\n",
        "def calculate_accuracy(str1, str2):\n",
        "    str1, str2 = str(str1).strip(), str(str2).strip()\n",
        "    if not str1 and not str2: return 100.0\n",
        "    return round(difflib.SequenceMatcher(None, str1, str2).ratio() * 100, 2)\n",
        "\n",
        "def get_comparison_data(gt_path, res_path):\n",
        "    with open(gt_path, 'r', encoding='utf-8') as f: gt = json.load(f)\n",
        "    with open(res_path, 'r', encoding='utf-8') as f: res = json.load(f)\n",
        "    data = []\n",
        "    # Header Fields\n",
        "    for k in gt: \n",
        "        if k == 'line_items': continue\n",
        "        v_gt = gt[k]\n",
        "        v_res = res.get(k, '')\n",
        "        acc = calculate_accuracy(v_gt, v_res)\n",
        "        data.append({\n",
        "            'Field': k, \n",
        "            'Accuracy': acc, \n",
        "            'Ground Truth': v_gt, \n",
        "            'Result': v_res, \n",
        "            'Category': 'Header', \n",
        "            'Weight': FIELD_WEIGHTS.get(k, 1.0)\n",
        "        })\n",
        "    # Line Items\n",
        "    for i, gi in enumerate(gt.get('line_items', [])):\n",
        "        ri = res.get('line_items', [])[i] if i < len(res.get('line_items', [])) else {}\n",
        "        for k, v in gi.items():\n",
        "            acc = calculate_accuracy(v, ri.get(k, ''))\n",
        "            data.append({\n",
        "                'Field': f'Item_{i+1}_{k}', \n",
        "                'Accuracy': acc, \n",
        "                'Ground Truth': v, \n",
        "                'Result': ri.get(k, ''), \n",
        "                'Category': 'Line Item', \n",
        "                'Weight': FIELD_WEIGHTS.get('line_items', {}).get(k, 1.0)\n",
        "            })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def generate_visual_report(df, filename):\n",
        "    if df.empty: return\n",
        "    doc_points = (df['Accuracy'] * df['Weight']).sum()\n",
        "    doc_weight = df['Weight'].sum()\n",
        "    score = doc_points / doc_weight if doc_weight > 0 else 0\n",
        "    batch_summary.append({'File': filename, 'Score': score, 'WP': doc_points, 'TW': doc_weight, 'Fields': len(df)})\n",
        "    \n",
        "    # Premium Header Card\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style='background: linear-gradient(135deg, #1e293b 0%, #334155 100%); padding: 30px; border-radius: 20px; color: white; margin-bottom: 30px; box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1);'>\n",
        "        <div style='display: flex; justify-content: space-between; align-items: center;'>\n",
        "            <div>\n",
        "                <h1 style='margin: 0; font-size: 32px; font-weight: 800; letter-spacing: -0.025em;'>Report: {filename}</h1>\n",
        "                <p style='margin: 5px 0 0 0; opacity: 0.7; font-size: 16px;'>Weighted Accuracy Analysis</p>\n",
        "            </div>\n",
        "            <div style='text-align: right;'>\n",
        "                <div style='font-size: 48px; font-weight: 900; line-height: 1;'>{score:.2f}%</div>\n",
        "                <div style='font-size: 14px; opacity: 0.6; margin-top: 5px;'>TOTAL SCORE</div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "    \n",
        "    # Bar Chart Styling\n",
        "    plt.figure(figsize=(12, len(df)*0.55))\n",
        "    colors = ['#ef4444' if x < 70 else '#f97316' if x < 85 else '#eab308' if x < 95 else '#10b981' for x in df['Accuracy']]\n",
        "    bars = plt.barh(df['Field'], df['Accuracy'], color=colors, height=0.7, edgecolor='white', linewidth=1)\n",
        "    plt.axvline(x=100, color='#e2e8f0', linestyle='-', linewidth=2, zorder=0)\n",
        "    for i, v in enumerate(df['Accuracy']):\n",
        "        plt.text(v + 1.5, i, f'{v:.1f}%', va='center', fontweight='800', color='#475569', fontsize=11)\n",
        "    plt.xlim(0, 115)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.gca().set_axisbelow(True)\n",
        "    plt.grid(axis='x', color='#f1f5f9', linestyle='-', linewidth=1)\n",
        "    plt.title(f'Accuracy Breakdown - {filename}', fontsize=16, pad=20, fontweight='bold', color='#1e293b')\n",
        "    plt.gca().spines['top'].set_visible(False)\n",
        "    plt.gca().spines['right'].set_visible(False)\n",
        "    plt.gca().spines['bottom'].set_color('#e2e8f0')\n",
        "    plt.gca().spines['left'].set_color('#e2e8f0')\n",
        "    plt.tick_params(colors='#64748b', labelsize=10)\n",
        "    plt.show()\n",
        "    \n",
        "    # Premium Table Implementation\n",
        "    def style_acc(v):\n",
        "        color = '#10b981' if v >= 95 else '#eab308' if v >= 85 else '#f97316' if v >= 70 else '#ef4444'\n",
        "        return f'color: {color}; font-weight: 800;'\n",
        "\n",
        "    styler = df[['Field', 'Accuracy', 'Weight', 'Ground Truth', 'Result', 'Category']].style.hide(axis='index')\\\n",
        "        .applymap(style_acc, subset=['Accuracy'])\\\n",
        "        .format({'Accuracy': '{:.1f}%', 'Weight': '{:.1f}x'})\\\n",
        "        .set_properties(**{\n",
        "            'text-align': 'left',\n",
        "            'padding': '16px 20px',\n",
        "            'border-bottom': '1px solid #f1f5f9',\n",
        "            'font-family': 'Inter, system-ui, sans-serif',\n",
        "            'font-size': '14px',\n",
        "            'color': '#334155'\n",
        "        })\\\n",
        "        .set_table_styles([\n",
        "            {'selector': 'th', 'props': [\n",
        "                ('background-color', '#f8fafc'),\n",
        "                ('color', '#64748b'),\n",
        "                ('font-weight', '700'),\n",
        "                ('text-transform', 'uppercase'),\n",
        "                ('font-size', '12px'),\n",
        "                ('letter-spacing', '0.05em'),\n",
        "                ('border-bottom', '2px solid #e2e8f0'),\n",
        "                ('padding', '12px 20px')\n",
        "            ]},\n",
        "            {'selector': 'tr:hover', 'props': [('background-color', '#f1f5f9')]}\n",
        "        ])\n",
        "    \n",
        "    display(HTML(styler.to_html()))\n",
        "\n",
        "res_dir = '/Users/pat/Desktop/custom_FM/working/comparison/result/updated_prompt_result/'\n",
        "gt_dir = '/Users/pat/Desktop/custom_FM/working/comparison/ground_truth/converted/'\n",
        "batch_summary = []\n",
        "for f in sorted(os.listdir(res_dir)):\n",
        "    if f.startswith('output_') and f.endswith('.json'):\n",
        "        fid = f[7:-5]\n",
        "        gp, rp = os.path.join(gt_dir, fid+'.json'), os.path.join(res_dir, f)\n",
        "        if os.path.exists(gp): generate_visual_report(get_comparison_data(gp, rp), fid)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TOTAL BATCH SUMMARY\n",
        "if batch_summary:\n",
        "    sdf = pd.DataFrame(batch_summary)\n",
        "    total_score = sdf['WP'].sum() / sdf['TW'].sum()\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style='background: linear-gradient(135deg, #4f46e5 0%, #7c3aed 100%); padding: 40px; border-radius: 24px; color: white; text-align: center; box-shadow: 0 20px 25px -5px rgba(0,0,0,0.1); margin: 40px 0;'>\n",
        "        <div style='font-size: 18px; opacity: 0.8; text-transform: uppercase; letter-spacing: 0.1em; font-weight: 600;'>Global Batch Accuracy</div>\n",
        "        <div style='font-size: 84px; font-weight: 900; margin: 10px 0;'>{total_score:.2f}%</div>\n",
        "        <div style='height: 4px; background: rgba(255,255,255,0.2); width: 100px; margin: 20px auto; border-radius: 2px;'></div>\n",
        "        <div style='font-size: 16px; opacity: 0.8;'>Analyzed {len(sdf)} documents across all datasets</div>\n",
        "    </div>\n",
        "    \"\"\"))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}